# TFIDF
TF-IDF (term frequency-inverse document frequency) is a numerical statistic that is used to evaluate how important a word is to a document in a collection or corpus of documents.

TF-IDF is calculated by multiplying two values: term frequency (TF) and inverse document frequency (IDF).

The term frequency (TF) measures how frequently a term appears in a document. It is calculated by counting the number of times a term appears in a document and dividing it by the total number of words in the document.

The inverse document frequency (IDF) measures how important a term is to the entire corpus of documents. It is calculated by dividing the total number of documents in the corpus by the number of documents that contain the term, and then taking the logarithm of the result.

The TF-IDF value for a term in a document is the product of its term frequency and inverse document frequency.

TF-IDF is often used in natural language processing (NLP) and text mining applications to determine the relevance of a word or phrase to a document or corpus of documents. It can be used for tasks such as keyword extraction, document classification, and information retrieval.
